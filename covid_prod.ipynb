{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *\n",
    "from fastai2.vision.widgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning tool for diagnosis and prognosis Covid-19\n",
    "\n",
    "This is a quick prototype developed for Lumiata Covid-19 Global AI hackathon event.This application loads the trained deep learning model and classifies the uploaded chest X-ray into any of the following category \n",
    "\n",
    "- Covid-19 \n",
    "- Normal\n",
    "- Pneumonia\n",
    "\n",
    "## Data\n",
    "- Covid-19 data : https://github.com/ieee8023/covid-chestxray-dataset/tree/master/images (Joseph Paul Cohen and Paul Morrison and Lan Dao)\n",
    "\n",
    "- Normal Chest X-ray, Pneumonia Chest X-ray images: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia (Kermany, Daniel; Zhang, Kang; Goldbaum, Michael (2018),)\n",
    "\n",
    "### Model trained on: (Latest data added on April 23, 2020)\n",
    "- Covid-19 X-ray data: 337 images\n",
    "- Normal Chest X-ray : 333 images\n",
    "- Pneumonia Chest X-ray: 328 images\n",
    "\n",
    "## Motivation\n",
    "\n",
    "When businesses reopen, we need a effective way to test masses. We need a tool to identiy covid-19 symptoms that is cheap, fast,easy to scale, and use existing infrastructure. Also after a successful diagnosis, we need to answer additional questions like:\n",
    "\n",
    "- Could this patient stay at home or need an ICU?\n",
    "- If a patient needs an ICU, in how many days?\n",
    "- What is the survival rate of this patient?\n",
    "- How he is going to respond to some particular treatment?\n",
    "\n",
    "Currently, our team is focused on building a diagnosis tool, and we are working on answering the above questions and add these additional features in our tool. In medical AI tools, it's important to be transparent about the model error metrics, data collection, peer review, and clinical study. We will be releasing these details along with our product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2 import __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner(path/'export.pkl', cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "out_pl = widgets.Output()\n",
    "lbl_pred = widgets.Label()\n",
    "btn_run = widgets.Button(description='Analyse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = PILImage.create(btn_upload.data[-1])\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: display(img.to_thumb(128,128))\n",
    "    pred,pred_idx,probs = learn_inf.predict(img)\n",
    "    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac84d67a5da4b2ea5ca0973a6ddbd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select your X-ray'), FileUpload(value={}, description='Upload'), Button(descriptioâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(VBox([widgets.Label('Select your X-ray'), btn_upload,  btn_run, out_pl, lbl_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About the model\n",
    "\n",
    "The deep learning model was developed using fastai framework and deployed using voila and render. \n",
    "### Training data sample\n",
    "![m](images/train.png)\n",
    "\n",
    "### Model Metrics\n",
    "![m](images/conf.png)\n",
    "![m](images/report.png)\n",
    "\n",
    "### Model Interpretation (Explainability)\n",
    "\n",
    "In applications like using AI in medicine, it's highly important to understand the reason behind a model prediction. For this explainability, we have started with coloring the area where our model focuses more for making some prediction. In future, we are planning to combine this with natural language processing to generate more reasoning behind our model predictions\n",
    "\n",
    "![m](images/interp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "\n",
    "We would like to thank the dataset providers (cited above) for making the dataset available for public access, also thank you Jeremy Howard and Team for creating fastai and making it accessible to everyone. Finally, we would like to thank the hackathon mentors and organisers for giving us an opportunity to contribute something to a big global cause."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
